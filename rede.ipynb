{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install rasterio"
      ],
      "metadata": {
        "id": "TTplcjuqxPLe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_qZsoBUp7oSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "27129fc8-bff3-469b-dabd-a36df85ecc93"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "duplicate registrations for aten.linspace.Tensor_Tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3808917765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2668\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mregister_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mout_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m def meta_linspace_logspace(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mpytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_map_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py\u001b[0m in \u001b[0;36mtree_map_\u001b[0;34m(func, tree, is_leaf, *rests)\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m     \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# consume and exhaust the iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mpytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_map_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m_add_op_to_registry\u001b[0;34m(registry, op, fn)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mop_overload\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moverloads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mop_overload\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"duplicate registrations for {op_overload}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m# TorchScript dumps a bunch of extra nonsense overloads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# which don't have corresponding dispatcher entries, we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: duplicate registrations for aten.linspace.Tensor_Tensor"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessamento\n",
        "class SuperResTiffDataset(Dataset):\n",
        "    def __init__(self, low_res_paths, high_res_paths, target_size=(128,128)):\n",
        "        self.low_res_paths = low_res_paths\n",
        "        self.high_res_paths = high_res_paths\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.low_res_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Lê baixa resolução\n",
        "        with rasterio.open(self.low_res_paths[idx]) as src:\n",
        "            low_res = src.read(1).astype(np.float32)\n",
        "\n",
        "        # Lê alta resolução\n",
        "        with rasterio.open(self.high_res_paths[idx]) as src:\n",
        "            high_res = src.read(1).astype(np.float32)\n",
        "\n",
        "        # Normaliza [0,1]\n",
        "        low_res = (low_res - np.min(low_res)) / (np.max(low_res) - np.min(low_res) + 1e-8)\n",
        "        high_res = (high_res - np.min(high_res)) / (np.max(high_res) - np.min(high_res) + 1e-8)\n",
        "\n",
        "        # Converte para tensores [1,H,W]\n",
        "        low_res = torch.from_numpy(low_res).unsqueeze(0)\n",
        "        high_res = torch.from_numpy(high_res).unsqueeze(0)\n",
        "\n",
        "        # Redimensiona para tamanho alvo\n",
        "        low_res = F.interpolate(low_res.unsqueeze(0), size=self.target_size, mode=\"bilinear\", align_corners=False).squeeze(0)\n",
        "        high_res = F.interpolate(high_res.unsqueeze(0), size=self.target_size, mode=\"bilinear\", align_corners=False).squeeze(0)\n",
        "\n",
        "        return low_res, high_res"
      ],
      "metadata": {
        "id": "D_TZns1lsr6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_ch, out_ch):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class UNetFinal(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, base_filters=16):\n",
        "        super().__init__()\n",
        "        f = base_filters\n",
        "\n",
        "        # Encoder (c_i são as saídas para as skip connections)\n",
        "        self.conv1 = conv_block(in_channels, f) # Saída: [B, f, H, W]\n",
        "        self.conv2 = conv_block(f, f*2) # Saída: [B, f*2, H/2, W/2]\n",
        "        self.conv3 = conv_block(f*2, f*4) # Saída: [B, f*4, H/4, W/4]\n",
        "        self.conv4 = conv_block(f*4, f*8) # Saída: [B, f*8, H/8, W/8]\n",
        "\n",
        "        # Pooling (p_i são as saídas para a próxima camada do encoder)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = conv_block(f*8, f*16) # Saída: [B, f*16, H/16, W/16]\n",
        "\n",
        "        # Decoder (u_i são as saídas das camadas de up-sampling)\n",
        "        # Note a correção nos canais de entrada da conv_up\n",
        "        self.up4 = nn.ConvTranspose2d(f*16, f*8, kernel_size=2, stride=2)\n",
        "        self.conv_up4 = conv_block(f*16, f*8) # Concatenado [f*8, f*8]\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(f*8, f*4, kernel_size=2, stride=2)\n",
        "        self.conv_up3 = conv_block(f*8, f*4) # Concatenado [f*4, f*4]\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(f*4, f*2, kernel_size=2, stride=2)\n",
        "        self.conv_up2 = conv_block(f*4, f*2) # Concatenado [f*2, f*2]\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(f*2, f, kernel_size=2, stride=2)\n",
        "        self.conv_up1 = conv_block(f*2, f) # Concatenado [f, f]\n",
        "\n",
        "        # Saída final\n",
        "        self.final_conv = nn.Conv2d(f, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        c1 = self.conv1(x)  # 128x128\n",
        "        p1 = self.pool(c1)  # 64x64\n",
        "\n",
        "        c2 = self.conv2(p1) # 64x64\n",
        "        p2 = self.pool(c2)  # 32x32\n",
        "\n",
        "        c3 = self.conv3(p2) # 32x32\n",
        "        p3 = self.pool(c3)  # 16x16\n",
        "\n",
        "        c4 = self.conv4(p3) # 16x16\n",
        "        p4 = self.pool(c4)  # 8x8\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p4) # 8x8\n",
        "\n",
        "        # Decoder\n",
        "        u4 = self.up4(b)    # 16x16\n",
        "        # Ajuste de tamanho para garantir que a concatenação funcione\n",
        "        u4 = F.interpolate(u4, size=c4.size()[2:], mode='bilinear', align_corners=False)\n",
        "        u4 = torch.cat([u4, c4], 1)\n",
        "        u4 = self.conv_up4(u4)\n",
        "\n",
        "        u3 = self.up3(u4)   # 32x32\n",
        "        # Ajuste de tamanho\n",
        "        u3 = F.interpolate(u3, size=c3.size()[2:], mode='bilinear', align_corners=False)\n",
        "        u3 = torch.cat([u3, c3], 1)\n",
        "        u3 = self.conv_up3(u3)\n",
        "\n",
        "        u2 = self.up2(u3)   # 64x64\n",
        "        # Ajuste de tamanho\n",
        "        u2 = F.interpolate(u2, size=c2.size()[2:], mode='bilinear', align_corners=False)\n",
        "        u2 = torch.cat([u2, c2], 1)\n",
        "        u2 = self.conv_up2(u2)\n",
        "\n",
        "        u1 = self.up1(u2)   # 128x128\n",
        "        # Ajuste de tamanho\n",
        "        u1 = F.interpolate(u1, size=c1.size()[2:], mode='bilinear', align_corners=False)\n",
        "        u1 = torch.cat([u1, c1], 1)\n",
        "        u1 = self.conv_up1(u1)\n",
        "\n",
        "        return self.final_conv(u1)\n"
      ],
      "metadata": {
        "id": "KE2ffn4t7vy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ajuste treinamento\n",
        "low_res_files = [\"recorte_anadem.tif\"]\n",
        "high_res_files = [\"recorte_geosampa.tif\"]\n",
        "\n",
        "dataset = SuperResTiffDataset(low_res_files, high_res_files, target_size=(128,128))\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "model = UNetFinal().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "H_YIEVEks5cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop\n",
        "epochs = 300\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (low_res, high_res) in enumerate(loader):\n",
        "        low_res, high_res = low_res.to(device), high_res.to(device)\n",
        "\n",
        "        preds = model(low_res)\n",
        "        loss = criterion(preds, high_res)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if batch_idx == 0 and epoch == 0:\n",
        "            print(f\"Low shape: {low_res.shape}, High shape: {high_res.shape}, Preds shape: {preds.shape}\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"unet_superres.pth\")\n",
        "print(\"Treinamento concluído e modelo salvo!\")"
      ],
      "metadata": {
        "id": "ohYPfOl2s8eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_superres_tif(model, low_res_tif, out_path, device):\n",
        "    model.eval()\n",
        "\n",
        "    with rasterio.open(low_res_tif) as src:\n",
        "        img = src.read(1).astype(np.float32)\n",
        "        profile = src.profile\n",
        "\n",
        "    img_norm = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
        "    img_tensor = torch.from_numpy(img_norm).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    # Redimensiona para 128x128 se necessário\n",
        "    img_tensor = F.interpolate(img_tensor, size=(128,128), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(img_tensor)\n",
        "\n",
        "    pred = pred.squeeze().cpu().numpy()\n",
        "    pred = pred * (np.max(img) - np.min(img)) + np.min(img)\n",
        "\n",
        "    profile.update(dtype=rasterio.float32)\n",
        "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
        "        dst.write(pred.astype(np.float32), 1)\n",
        "\n",
        "    print(f\"Super-resolução salva em: {out_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "TOjOKyjGs_tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Exemplo de inferência\n",
        "gerar_superres_tif(model, \"testeeee.tif\", \"saida_testeee.tif\", device)"
      ],
      "metadata": {
        "id": "sJ62FZhyxay9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rasterio.plot import show\n",
        "raster = rasterio.open(\"saida_testeee.tif\")\n",
        "show(raster)"
      ],
      "metadata": {
        "id": "-YKD1FxIxwxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "802hDvb1Lu3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}